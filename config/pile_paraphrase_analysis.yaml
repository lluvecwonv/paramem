# Pile Paraphrase Analysis Configuration

model_family: pythia-2.8b

# Pile samples directory (JSONL files from sample_pile_data.py)
pile_samples_dir: ./pile_samples

# Number of samples to paraphrase per file (null = all)
num_samples: null

min_samples_per_bin: 10

analysis:
  batch_size: 1  # Low memory mode (only 21MB GPU free)
  num_paraphrases: 3  # Generate 3 paraphrases per text
  output_dir: results
  generation_mode: beam_single_prompt  # Beam search with single prompt (fast!)
  num_beams: 3  # Reduced from 4 to save memory (must be >= num_paraphrases)
  paraphrase_temperature: 0.25  # Structure-preserving temperature
  top_p: 0.9  # Controlled nucleus sampling
  top_k: 40  # Cut off probability tail (prevent non-grammatical tokens)
  repetition_penalty: 1.1  # Suppress repetition of original words
  length_penalty: 1.0  # Neutral (avoid length bias)
  use_soft_beam_sampling: true  # Enable controlled sampling (do_sample=True + beam search)

generation:
  max_length: 512
  max_new_tokens: 256

device: cuda
local_rank: 0
