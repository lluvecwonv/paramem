[2025-10-29 09:28:54,532][memorization.utils][INFO] - Loaded config for pythia-2.8b: EleutherAI/pythia-2.8b
[2025-10-29 09:29:00,334][memorization.analysis.paraphrase_generator][INFO] - ParaphraseGenerator initialized: mode=beam_single_prompt, num_paraphrases=3, num_beams=3, temperature=0.25, top_p=0.9
[2025-10-29 09:30:49,805][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:32:12,485][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:33:26,561][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:35:15,057][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:36:54,047][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:38:41,176][memorization.analysis.paraphrase_generator][ERROR] - Batch generation failed: CUDA out of memory. Tried to allocate 146.00 MiB. GPU 0 has a total capacty of 47.53 GiB of which 7.94 MiB is free. Process 3823831 has 6.28 GiB memory in use. Process 3827963 has 41.19 GiB memory in use. Of the allocated memory 37.74 GiB is allocated by PyTorch, and 2.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, falling back to sequential
[2025-10-29 09:38:41,180][memorization.analysis.paraphrase_generation_utils][INFO] - Using controlled sampling (temperature=0.25, top_p=0.9)
[2025-10-29 09:38:41,840][memorization.analysis.paraphrase_generation_utils][ERROR] - Beam search failed: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacty of 47.53 GiB of which 7.94 MiB is free. Process 3823831 has 6.28 GiB memory in use. Process 3827963 has 41.19 GiB memory in use. Of the allocated memory 39.07 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-10-29 09:38:41,845][memorization.analysis.paraphrase_generation_utils][INFO] - Using controlled sampling (temperature=0.25, top_p=0.9)
[2025-10-29 09:38:42,701][memorization.analysis.paraphrase_generation_utils][ERROR] - Beam search failed: CUDA out of memory. Tried to allocate 266.00 MiB. GPU 0 has a total capacty of 47.53 GiB of which 7.94 MiB is free. Process 3823831 has 6.28 GiB memory in use. Process 3827963 has 41.19 GiB memory in use. Of the allocated memory 39.43 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-10-29 09:38:42,706][memorization.analysis.paraphrase_generation_utils][INFO] - Using controlled sampling (temperature=0.25, top_p=0.9)
[2025-10-29 09:38:43,435][memorization.analysis.paraphrase_generation_utils][ERROR] - Beam search failed: CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacty of 47.53 GiB of which 7.94 MiB is free. Process 3823831 has 6.28 GiB memory in use. Process 3827963 has 41.19 GiB memory in use. Of the allocated memory 39.24 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-10-29 09:38:43,440][memorization.analysis.paraphrase_generation_utils][INFO] - Using controlled sampling (temperature=0.25, top_p=0.9)
[2025-10-29 09:38:44,099][memorization.analysis.paraphrase_generation_utils][ERROR] - Beam search failed: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 47.53 GiB of which 7.94 MiB is free. Process 3823831 has 6.28 GiB memory in use. Process 3827963 has 41.19 GiB memory in use. Of the allocated memory 39.00 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2025-10-29 09:40:19,647][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:41:46,147][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
[2025-10-29 09:43:14,342][memorization.analysis.paraphrase_generator][INFO] - ✅ Batch generated paraphrases for 4 texts
